"""
"""
import os
import re

import six
from sceptre.hooks import Hook

from devops import util
from devops.api.ecr import ecr_login

LOGGER = util.get_logger("hooks." + __name__)

AWS_CONTAINER = "amazon/aws-cli:2.11.1"
HELM_CONTAINER = "870326185936.dkr.ecr.us-east-2.amazonaws.com/605data/helm:5500021141a23984fd04c19822da8b78c6709784"
KUBECTL_CONTAINER = HELM_CONTAINER


class EksHook(Hook):
    """ """

    @property
    def cluster_name(self):
        """
        helper for pulling cluster name from the eksctl config.
        NB: path below is demanded by, but coupled to, eksctl config schema
        """
        return self.stack.raw_config["eksctl_user_data"]["metadata"]["name"]

    @property
    def kubeconfig_file(self):
        # return os.path.expanduser(
        return "~/.kube/{}-{}.yaml".format(os.environ["env"], self.cluster_name)
        # )

    @property
    def docker_volume_root(self):
        """ """
        if "DOCKER_VOLUME_ROOT" in os.environ:
            tmp = os.environ["DOCKER_VOLUME_ROOT"]
            return tmp
        else:
            LOGGER.debug("DOCKER_VOLUME_ROOT is missing, using ~")
            return "~"

    def init_kubeconfig(self):
        """prepares helm profile for this eks cluster"""
        cmd_t = (
            "AWS_PROFILE={profile} "
            "AWS_DEFAULT_REGION={region} "
            "KUBECONFIG='{kubeconfig_file}' "
            "aws eks update-kubeconfig --name {cluster_name}"
        )
        inner_cmd = cmd_t.format(
            profile=self.stack.profile,
            region=self.stack.region,
            kubeconfig_file=self.kubeconfig_file,
            cluster_name=self.cluster_name,
        )
        cmd_t = (
            "docker run --entrypoint bash "
            "-v {docker_home}/.kube:/root/.kube "
            "-v {docker_home}/.aws:/root/.aws "
            "-v `pwd`:/workspace "
            "-w /workspace "
            '{container} -x -c "{cmd}"'
        )
        ecr_login()
        error = self.invoke(
            cmd_t.format(
                docker_home=self.docker_volume_root,
                container=AWS_CONTAINER,
                cmd=inner_cmd,
            )
        )
        if error:
            raise SystemExit(1)

    @util.timeit
    def invoke(self, cmd):
        """runs command with the usual wrapper for logging"""
        LOGGER.warning("")
        LOGGER.warning("EXEC â‡¨")
        LOGGER.warning("\n{}".format(cmd))
        LOGGER.warning("")
        LOGGER.debug("")
        return os.system(cmd)

    def invoke_helm(self, cmd=None):
        """
        actually runs eksctl with the given command,
        for example `create-cluster`.  NB: some arguments
        are autogenerated/appended so you shouldn't pass them.
        """
        cmd_t = (
            "docker run "
            "-v {docker_home}/.kube:/root/.kube "
            "-v {docker_home}/.aws:/root/.aws "
            "-e KUBECONFIG={kubeconfig} "
            "--entrypoint sh {helm_container} -x -c '{helm_cmd}'"
        )
        ecr_login()
        error = self.invoke(
            cmd_t.format(
                docker_home=self.docker_volume_root,
                kubeconfig="'/root/.kube/{}-{}.yaml'".format(
                    os.environ["env"], self.cluster_name
                ),
                helm_container=HELM_CONTAINER,
                helm_cmd=self.argument,
            )
        )
        if error:
            raise SystemExit(1)

    def invoke_kubectl(self, cmd=None):
        """
        actually runs eksctl with the given command,
        for example `create-cluster`.  NB: some arguments
        are autogenerated/appended so you shouldn't pass them.
        """
        # case is checked first so that kubectl can auth afterwards.
        if cmd == "init":
            self.init_kubeconfig()

        # case proxies to kubectl with eks auth preconfigured
        else:
            # checks for something like `!kubectl apply -f @some.yaml.path,`
            # if this syntax is found we dereference the path, throw the
            # contents in a tmp file, then run kubectl on it as usual
            refs = re.findall("\@\w+", self.argument)  # noqa
            if refs:
                for anchor_dotpath in refs:
                    dotpath = anchor_dotpath[1:]  # knock off '@'
                    fname = ".kubectl.{}.yaml".format(dotpath)
                    msg = "unpacking nested config for `{}` to {}"
                    LOGGER.debug(msg.format(dotpath, fname))
                    dotpath = [x for x in dotpath.split(".") if x.strip()]
                    config = self.stack.raw_config
                    while dotpath:  # drill down to de-reference dotpath
                        next = dotpath.pop(0)
                        config = config[next]
                    err = "only string-type arguments for @anchors is allowed"
                    assert isinstance(config, six.string_types), err
                    LOGGER.debug("unpacked: \n{}".format(
                        util.indent(str(config), 2)))
                    with open(fname, "w") as fhandle:
                        fhandle.write(config)
                    self.argument = self.argument.replace(
                        anchor_dotpath, fname)

            # set the kubeconfig for this cluster, then proxy to kubectl as requested
            cmd = "KUBECONFIG='{}' {}".format(
                self.kubeconfig_file, self.argument)
            return self.invoke(cmd)
